{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c013ca3",
   "metadata": {},
   "source": [
    "## **IE7275 — Project‑Based Assessment 1: Build a Recommendation System**\n",
    "\n",
    "---\n",
    "\n",
    "**Time limit:** 90 minutes  \n",
    "**Dataset:** `movielens_1m.csv`   \n",
    "**Format:** Individual work in this notebook (submit `.ipynb`)\n",
    "\n",
    "**Goal:** Build and evaluate a recommendation system using any technique(s) you prefer (collaborative filtering, content-based, hybrid, matrix factorization, neural methods, etc.).\n",
    "\n",
    "**What to submit:** A runnable notebook with your code, metrics, and short analysis.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149fae6e",
   "metadata": {},
   "source": [
    "## Dataset overview\n",
    "- **File**: `movielens_1m.csv` (~91.1 MB)\n",
    "- **Columns**: UserID, MovieID, Rating, Timestamp, Gender, Age, Occupation, Zip-code, Title, Genres, Datetime\n",
    "- **User column**: `UserID`\n",
    "- **Item column**: `MovieID`\n",
    "- **Rating column**: `Rating` (min=1.0, max=5.0, mean≈3.56)\n",
    "- **Timestamp column**: `Timestamp` (range: 2000-11-21 19:59:26 → 2003-02-27 23:31:15)\n",
    "- **Title column**: `Title`\n",
    "- **Genres column**: `Genres` (pipe‑separated or delimited string)\n",
    "- **Approx. unique users/items in sample**: 1,228 users / 3,463 items (from a sample of the file)\n",
    "\n",
    "**Notes:**\n",
    "- Ratings are explicit (e.g., 1–5 stars) if a rating column is provided; otherwise you may treat interactions as implicit feedback.\n",
    "- If a timestamp is present, prefer a **time‑aware split** (train on earlier interactions, test on later).\n",
    "- For content features, you may parse the **genres** and/or use **titles** (e.g., TF‑IDF of titles) for hybrid models.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c31ff6",
   "metadata": {},
   "source": [
    "## Rules & Deliverables\n",
    "\n",
    "**You may use any libraries** (e.g., `pandas`, `numpy`, `scikit-learn`, `surprise`, `implicit`, `lightfm`, `tensorflow/pytorch`). If installing extra packages, include the install cell (and keep it lightweight).\n",
    "\n",
    "### Required deliverables\n",
    "1. **Preprocessing summary** (brief): how you cleaned/filtered the data.\n",
    "2. **Two recommendation approaches** (any mix, e.g., Popularity baseline + Item‑CF; MF + Content‑based; Hybrid; etc.).\n",
    "3. **Evaluation** with at least **two ranking metrics** (e.g., Precision@k, Recall@k, Hit Rate, MAP@k, NDCG@k). Use a **time‑aware split** if timestamps exist, otherwise use a user‑stratified split.\n",
    "4. **Results & brief discussion**: a short comparison of the two approaches, trade‑offs, and observations (sparsity, cold‑start, bias, etc.).\n",
    "5. **Top‑N recommendations** for **5 sample users** with brief justification.\n",
    "\n",
    "### Suggested timeboxing\n",
    "- Data understanding & prep: ~15 min  \n",
    "- Modeling (2 approaches): ~40 min  \n",
    "- Evaluation & analysis: ~25 min  \n",
    "- Wrap‑up: ~10 min\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f2e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: install extra libraries if needed (uncomment)\n",
    "# %pip install scikit-surprise implicit lightfm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d305bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports & configuration\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "RNG_SEED = 42\n",
    "random.seed(RNG_SEED)\n",
    "np.random.seed(RNG_SEED)\n",
    "\n",
    "DATA_PATH = \"movielens_1m.csv\"\n",
    "assert os.path.exists(DATA_PATH), f\"Dataset not found at {DATA_PATH}. Please upload or fix the path.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7741a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000209, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>MovieID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Zip-code</th>\n",
       "      <th>Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>One Flew Over the Cuckoo's Nest (1975)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2000-12-31 22:12:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>James and the Giant Peach (1996)</td>\n",
       "      <td>Animation|Children's|Musical</td>\n",
       "      <td>2000-12-31 22:35:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>My Fair Lady (1964)</td>\n",
       "      <td>Musical|Romance</td>\n",
       "      <td>2000-12-31 22:32:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Erin Brockovich (2000)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>2000-12-31 22:04:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Bug's Life, A (1998)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "      <td>2001-01-06 23:38:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  MovieID  Rating  Timestamp Gender  Age  Occupation Zip-code  \\\n",
       "0       1     1193       5  978300760      F    1          10    48067   \n",
       "1       1      661       3  978302109      F    1          10    48067   \n",
       "2       1      914       3  978301968      F    1          10    48067   \n",
       "3       1     3408       4  978300275      F    1          10    48067   \n",
       "4       1     2355       5  978824291      F    1          10    48067   \n",
       "\n",
       "                                    Title                        Genres  \\\n",
       "0  One Flew Over the Cuckoo's Nest (1975)                         Drama   \n",
       "1        James and the Giant Peach (1996)  Animation|Children's|Musical   \n",
       "2                     My Fair Lady (1964)               Musical|Romance   \n",
       "3                  Erin Brockovich (2000)                         Drama   \n",
       "4                    Bug's Life, A (1998)   Animation|Children's|Comedy   \n",
       "\n",
       "              Datetime  \n",
       "0  2000-12-31 22:12:40  \n",
       "1  2000-12-31 22:35:09  \n",
       "2  2000-12-31 22:32:48  \n",
       "3  2000-12-31 22:04:35  \n",
       "4  2001-01-06 23:38:11  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cc016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['UserID', 'MovieID', 'Rating', 'Timestamp', 'Gender', 'Age', 'Occupation', 'Zip-code', 'Title', 'Genres', 'Datetime']\n",
      "Null counts:\n",
      " UserID        0\n",
      "MovieID       0\n",
      "Rating        0\n",
      "Timestamp     0\n",
      "Gender        0\n",
      "Age           0\n",
      "Occupation    0\n",
      "Zip-code      0\n",
      "Title         0\n",
      "Genres        0\n",
      "Datetime      0\n",
      "dtype: int64\n",
      "Rating column detected: Rating\n",
      "count    1.000209e+06\n",
      "mean     3.581564e+00\n",
      "std      1.117102e+00\n",
      "min      1.000000e+00\n",
      "25%      3.000000e+00\n",
      "50%      4.000000e+00\n",
      "75%      4.000000e+00\n",
      "max      5.000000e+00\n",
      "Name: Rating, dtype: float64\n",
      "Time coverage: 2000-04-25 23:05:32 -> 2003-02-28 17:49:50\n"
     ]
    }
   ],
   "source": [
    "# 3) Quick sanity checks\n",
    "print(\"Columns:\", list(df.columns))\n",
    "print(\"Null counts:\\n\", df.isna().sum())\n",
    "\n",
    "# Peek at basic stats for ratings if present\n",
    "rating_col_candidates = [c for c in df.columns if c.lower() in [\"rating\",\"rate\",\"score\",\"stars\"]]\n",
    "if rating_col_candidates:\n",
    "    rc = rating_col_candidates[0]\n",
    "    print(f\"Rating column detected: {rc}\")\n",
    "    print(df[rc].describe())\n",
    "\n",
    "# If timestamp column exists, convert a copy to datetime for inspection\n",
    "ts_candidates = [c for c in df.columns if c.lower() in [\"timestamp\",\"time\",\"datetime\",\"date\"]]\n",
    "if ts_candidates:\n",
    "    tc = ts_candidates[0]\n",
    "    try:\n",
    "        # Try epoch seconds first\n",
    "        dt = pd.to_datetime(df[tc], unit=\"s\", errors=\"coerce\")\n",
    "        if dt.notna().mean() < 0.5:\n",
    "            # Fallback: parse direct\n",
    "            dt = pd.to_datetime(df[tc], errors=\"coerce\")\n",
    "        print(\"Time coverage:\", dt.min(), \"->\", dt.max())\n",
    "    except Exception as e:\n",
    "        print(\"Timestamp parse note:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edb93d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using columns -> UserID MovieID Rating Timestamp\n",
      "\n",
      "---Preprocessing Summary ---\n",
      "Post-prep shape: (999611, 11)\n",
      "Unique Users: 6040, Unique Items: 3416\n"
     ]
    }
   ],
   "source": [
    "# 4) Preprocessing — TODOs\n",
    "# - Define user_col, item_col, and (optionally) rating_col, ts_col\n",
    "# - Handle duplicates/missing\n",
    "# - Optional: filter very rare users/items (e.g., min 5 interactions)\n",
    "# - Optional: parse genres (split by '|' or other delimiter), create content features\n",
    "# - Decide: explicit (ratings) vs implicit (binary interactions)\n",
    "\n",
    "# >>> START HERE <<<\n",
    "# Example: infer standard column names (edit as needed)\n",
    "user_col = next((c for c in df.columns if c.lower() in [\"userid\",\"user_id\",\"user\"]), None)\n",
    "item_col = next((c for c in df.columns if c.lower() in [\"movieid\",\"movie_id\",\"itemid\",\"item_id\",\"movie\",\"item\"]), None)\n",
    "rating_col = next((c for c in df.columns if c.lower() in [\"rating\",\"rate\",\"score\",\"stars\"]), None)\n",
    "ts_col = next((c for c in df.columns if c.lower() in [\"timestamp\",\"time\",\"datetime\",\"date\"]), None)\n",
    "\n",
    "user_col = 'UserID'\n",
    "item_col = 'MovieID'\n",
    "rating_col = 'Rating'\n",
    "ts_col = 'Timestamp'\n",
    "\n",
    "print(\"Using columns ->\", user_col, item_col, rating_col, ts_col)\n",
    "\n",
    "user_col = 'UserID'\n",
    "item_col = 'MovieID'\n",
    "rating_col = 'Rating'\n",
    "ts_col = 'Timestamp'\n",
    "\n",
    "print(f\"\\n---Preprocessing Summary ---\")\n",
    "\n",
    "# **TODO: Preprocessing implementation**\n",
    "\n",
    "df = df.dropna(subset=[user_col, item_col, rating_col])\n",
    "\n",
    "df = df.drop_duplicates(subset=[user_col, item_col, ts_col])\n",
    "\n",
    "min_user_inter = 5\n",
    "min_item_inter = 5\n",
    "vc_users = df[user_col].value_counts()\n",
    "vc_items = df[item_col].value_counts()\n",
    "df = df[df[user_col].isin(vc_users[vc_users >= min_user_inter].index)]\n",
    "df = df[df[item_col].isin(vc_items[vc_items >= min_item_inter].index)]\n",
    "\n",
    "print(f\"Post-prep shape: {df.shape}\")\n",
    "print(f\"Unique Users: {df[user_col].nunique()}, Unique Items: {df[item_col].nunique()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "379cdbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((797275, 11), (202336, 11))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Train/validation/test split helpers\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "def time_aware_split(df, user_col, ts_col, train_frac=0.8):\n",
    "    \"\"\"Per user, sort by timestamp and split earliest -> train, latest -> test/val.\n",
    "    Returns a dict with train and test DataFrames.\n",
    "    \"\"\"\n",
    "    assert ts_col in df.columns, \"Timestamp column required for time‑aware split.\"\n",
    "    parts = []\n",
    "    for u, grp in df.sort_values(ts_col).groupby(user_col):\n",
    "        n = len(grp)\n",
    "        cut = max(1, int(n * train_frac))\n",
    "        parts.append((grp.iloc[:cut], grp.iloc[cut:]))\n",
    "    train = pd.concat([p[0] for p in parts], ignore_index=True)\n",
    "    test  = pd.concat([p[1] for p in parts], ignore_index=True)\n",
    "    return { \"train\": train, \"test\": test }\n",
    "\n",
    "def stratified_user_holdout(df, user_col, holdout=1):\n",
    "    \"\"\"If no timestamps available: keep last `holdout` interactions per user for test (by index order).\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for u, grp in df.groupby(user_col):\n",
    "        if len(grp) <= holdout:\n",
    "            tr = grp.iloc[:-1] if len(grp) > 1 else grp.iloc[:0]\n",
    "            te = grp.iloc[-1:]\n",
    "        else:\n",
    "            tr = grp.iloc[:-holdout]\n",
    "            te = grp.iloc[-holdout:]\n",
    "        parts.append((tr, te))\n",
    "    train = pd.concat([p[0] for p in parts], ignore_index=True)\n",
    "    test  = pd.concat([p[1] for p in parts], ignore_index=True)\n",
    "    return { \"train\": train, \"test\": test }\n",
    "\n",
    "# Choose split\n",
    "if ts_col:\n",
    "    splits = time_aware_split(df, user_col, ts_col, train_frac=0.8)\n",
    "else:\n",
    "    splits = stratified_user_holdout(df, user_col, holdout=1)\n",
    "\n",
    "train_df, test_df = splits[\"train\"], splits[\"test\"]\n",
    "train_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf967fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Ranking metrics (provided)\n",
    "from collections import defaultdict\n",
    "\n",
    "def precision_at_k(recommended: list, ground_truth: set, k=10):\n",
    "    rec_k = recommended[:k]\n",
    "    if not rec_k:\n",
    "        return 0.0\n",
    "    hit = sum(1 for x in rec_k if x in ground_truth)\n",
    "    return hit / len(rec_k)\n",
    "\n",
    "def recall_at_k(recommended: list, ground_truth: set, k=10):\n",
    "    if not ground_truth:\n",
    "        return 0.0\n",
    "    rec_k = recommended[:k]\n",
    "    hit = sum(1 for x in rec_k if x in ground_truth)\n",
    "    return hit / len(ground_truth)\n",
    "\n",
    "def apk(recommended: list, ground_truth: set, k=10):\n",
    "    if not ground_truth:\n",
    "        return 0.0\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, p in enumerate(recommended[:k], start=1):\n",
    "        if p in ground_truth:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / min(len(ground_truth), k) if ground_truth else 0.0\n",
    "\n",
    "def ndcg_at_k(recommended: list, ground_truth: set, k=10):\n",
    "    def dcg(rel):\n",
    "        return sum((1.0/np.log2(i+2)) for i, r in enumerate(rel) if r)\n",
    "    rel = [1 if x in ground_truth else 0 for x in recommended[:k]]\n",
    "    idcg = dcg(sorted(rel, reverse=True))\n",
    "    return dcg(rel) / idcg if idcg > 0 else 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3477242a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53, 167, 3905, 3245, 2503, 1164, 2930, 2444, 2905, 2019]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7) Baseline recommender: global popularity (works for implicit or explicit)\n",
    "# For explicit ratings, popularity ~ average rating; for implicit, popularity ~ #interactions\n",
    "\n",
    "if rating_col:\n",
    "    item_pop = train_df.groupby(item_col)[rating_col].mean().sort_values(ascending=False)\n",
    "else:\n",
    "    item_pop = train_df.groupby(item_col)[user_col].count().sort_values(ascending=False)\n",
    "\n",
    "popular_items = list(item_pop.index)\n",
    "\n",
    "def recommend_popularity(user_id, k=10, seen_items=None):\n",
    "    seen = set() if seen_items is None else set(seen_items)\n",
    "    recs = [it for it in popular_items if it not in seen]\n",
    "    return recs[:k]\n",
    "\n",
    "# Example usage for one user:\n",
    "u0 = train_df[user_col].iloc[0]\n",
    "seen_u0 = train_df.loc[train_df[user_col]==u0, item_col].unique()\n",
    "recommend_popularity(u0, k=10, seen_items=seen_u0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebfbf28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 7) Training Item-CF Model ---\n",
      "User-Item Matrix shape: (6040, 3415)\n",
      "\n",
      "--- 7.5) Training Content-Based (Genre) Model ---\n",
      "Item-Genre Matrix shape: (3415, 18)\n"
     ]
    }
   ],
   "source": [
    "# 8) Your model(s) — TODO\n",
    "# Build at least ONE personalized recommender in addition to the popularity baseline.\n",
    "# Ideas (choose any):\n",
    "# - Item‑based or user‑based collaborative filtering with cosine similarity\n",
    "# - Matrix factorization (e.g., SVD) with explicit ratings\n",
    "# - Implicit MF / LightFM (for implicit feedback)\n",
    "# - Content‑based (TF‑IDF on titles; one‑hot/embedding for genres), or Hybrid\n",
    "\n",
    "# >>> Implement your chosen model(s) below. <<<\n",
    "\n",
    "\n",
    "# Model A: Popularity Baseline ---\n",
    "# Using average rating for popularity\n",
    "item_pop = train_df.groupby(item_col)[rating_col].mean().sort_values(ascending=False)\n",
    "popular_items = list(item_pop.index)\n",
    "\n",
    "def recommend_popularity(user_id, k=10, seen_items=None):\n",
    "    seen = set() if seen_items is None else set(seen_items)\n",
    "    recs = [it for it in popular_items if it not in seen]\n",
    "    return recs[:k]\n",
    "\n",
    "# Model B: Item-Item Collaborative Filtering (Item-CF) ---\n",
    "print(\"\\n--- 7) Training Item-CF Model ---\")\n",
    "\n",
    "R = train_df.pivot_table(\n",
    "    index=user_col, \n",
    "    columns=item_col, \n",
    "    values=rating_col, \n",
    "    aggfunc='mean'\n",
    ").fillna(0)\n",
    "print(f\"User-Item Matrix shape: {R.shape}\")\n",
    "\n",
    "\n",
    "item_sim = cosine_similarity(R.T)\n",
    "\n",
    "item_list = R.columns.tolist()\n",
    "item_index_map = {item: idx for idx, item in enumerate(item_list)}\n",
    "\n",
    "def recommend_itemcf(user_id, k=10):\n",
    "    # Handle cold-start user\n",
    "    if user_id not in R.index:\n",
    "        return recommend_popularity(user_id, k)\n",
    "\n",
    "    user_vector = R.loc[user_id].values\n",
    "    scores = item_sim.dot(user_vector)\n",
    "    seen_mask = (user_vector > 0)\n",
    "    seen_items = set(R.columns[seen_mask])\n",
    "    ranked_indices = np.argsort(-scores)\n",
    "    ranked_items = [item_list[idx] for idx in ranked_indices]\n",
    "    recs = [it for it in ranked_items if it not in seen_items]\n",
    "    return list(recs)[:k]\n",
    "\n",
    "# Model C: Content-Based Filtering (Genres) ---\n",
    "print(\"\\n--- 7.5) Training Content-Based (Genre) Model ---\")\n",
    "content_df = df[[item_col, 'Genres']].drop_duplicates().set_index(item_col)\n",
    "\n",
    "genre_matrix = content_df['Genres'].str.get_dummies(sep='|')\n",
    "\n",
    "train_items = R.columns\n",
    "genre_matrix = genre_matrix.loc[genre_matrix.index.intersection(train_items)] \n",
    "print(f\"Item-Genre Matrix shape: {genre_matrix.shape}\")\n",
    "\n",
    "content_item_list = genre_matrix.index.tolist()\n",
    "content_item_index_map = {item: idx for idx, item in enumerate(content_item_list)}\n",
    "\n",
    "\n",
    "def recommend_content_based(user_id, k=10):\n",
    "    if user_id not in R.index:\n",
    "        return recommend_popularity(user_id, k)\n",
    "\n",
    "    user_ratings = R.loc[user_id]\n",
    "    user_seen_items = user_ratings[user_ratings > 0].index\n",
    "    \n",
    "    user_profile = np.zeros(genre_matrix.shape[1])\n",
    "    total_rating_sum = 0\n",
    "    \n",
    "    for item_id in user_seen_items:\n",
    "        if item_id in content_item_list:\n",
    "            rating = user_ratings.loc[item_id]\n",
    "            user_profile += genre_matrix.loc[item_id].values * rating\n",
    "            total_rating_sum += rating\n",
    "\n",
    "    if total_rating_sum > 0:\n",
    "        user_profile /= total_rating_sum\n",
    "    else:\n",
    "        return recommend_popularity(user_id, k)\n",
    "\n",
    "    candidate_items = genre_matrix.index\n",
    "    scores = genre_matrix.dot(user_profile)\n",
    "    \n",
    "    ranked_indices = np.argsort(-scores.values)\n",
    "    ranked_items = [candidate_items[idx] for idx in ranked_indices]\n",
    "\n",
    "    seen = set(user_seen_items)\n",
    "    recs = [it for it in ranked_items if it not in seen]\n",
    "    return list(recs)[:k]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a9c608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popularity@10 — precision: 0.002  recall: 0.001  MAP: 0.000  NDCG: 0.007\n",
      "\n",
      "--- 8) Evaluation for K=10 ---\n",
      "\n",
      "=== Model Performance Summary ===\n",
      "\n",
      "Model_A\n",
      "precision@10: 0.0021\n",
      "recall@10: 0.0010\n",
      "map@10: 0.0003\n",
      "ndcg@10: 0.0062\n",
      "n_users_eval: 1000\n",
      "\n",
      "Model_B\n",
      "precision@10: 0.1105\n",
      "recall@10: 0.0889\n",
      "map@10: 0.0673\n",
      "ndcg@10: 0.3145\n",
      "n_users_eval: 1000\n",
      "\n",
      "Model_C\n",
      "precision@10: 0.0185\n",
      "recall@10: 0.0168\n",
      "map@10: 0.0080\n",
      "ndcg@10: 0.0737\n",
      "n_users_eval: 1000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 9) Evaluation — TODO\n",
    "# Evaluate popularity baseline and your model(s) using at least two metrics (Precision@k, Recall@k, MAP@k, NDCG@k).\n",
    "# Use k=10 (and optionally 20). Consider time‑aware split correctness.\n",
    "\n",
    "def user_ground_truth(df_user,threshold=3.5):\n",
    "    # For explicit: treat items in test as relevant if rating >= threshold (choose threshold)\n",
    "    # For implicit: all test items are relevant\n",
    "    #return set(df_user[item_col].unique())\n",
    "    return set(df_user.loc[df_user[rating_col] >= threshold, item_col].unique())\n",
    "\n",
    "K = 10\n",
    "users = test_df[user_col].unique()[:1000]  # cap for speed\n",
    "\n",
    "pop_metrics = {\"precision\": [], \"recall\": [], \"map\": [], \"ndcg\": []}\n",
    "\n",
    "for u in users:\n",
    "    seen = train_df.loc[train_df[user_col]==u, item_col].unique()\n",
    "    gt = user_ground_truth(test_df.loc[test_df[user_col]==u])\n",
    "    if not gt: \n",
    "        continue\n",
    "    recs = recommend_popularity(u, k=K, seen_items=seen)\n",
    "    pop_metrics[\"precision\"].append(precision_at_k(recs, gt, k=K))\n",
    "    pop_metrics[\"recall\"].append(recall_at_k(recs, gt, k=K))\n",
    "    pop_metrics[\"map\"].append(apk(recs, gt, k=K))\n",
    "    pop_metrics[\"ndcg\"].append(ndcg_at_k(recs, gt, k=K))\n",
    "\n",
    "print(\"Popularity@10 — precision: %.3f  recall: %.3f  MAP: %.3f  NDCG: %.3f\" %\n",
    "      (np.mean(pop_metrics[\"precision\"]), np.mean(pop_metrics[\"recall\"]),\n",
    "       np.mean(pop_metrics[\"map\"]), np.mean(pop_metrics[\"ndcg\"])))\n",
    "\n",
    "# TODO: repeat for your model(s) and compare\n",
    "\n",
    "print(\"\\n------ Evaluation for K=10 ---\")\n",
    "\n",
    "K = 10\n",
    "\n",
    "users_to_evaluate = test_df[user_col].unique()[:min(1000, test_df[user_col].nunique())] \n",
    "\n",
    "models = {\n",
    "    \"Model_A\": recommend_popularity,    \n",
    "    \"Model_B\": recommend_itemcf,       \n",
    "    \"Model_C\": recommend_content_based  \n",
    "}\n",
    "metric_names = [\"precision@10\", \"recall@10\", \"map@10\", \"ndcg@10\"] \n",
    "results = {}\n",
    "\n",
    "num_users_evaluated = len(users_to_evaluate)\n",
    "\n",
    "for model_name, recommender_func in models.items():\n",
    "    metrics = defaultdict(list)\n",
    "    \n",
    "    for u in users_to_evaluate:\n",
    "        seen = train_df.loc[train_df[user_col] == u, item_col].unique()\n",
    "        \n",
    "        gt = user_ground_truth(test_df.loc[test_df[user_col] == u], threshold=3.5)\n",
    "        \n",
    "        if not gt: \n",
    "            continue\n",
    "            \n",
    "        recs = recommender_func(u, k=K)\n",
    "\n",
    "        metrics[\"precision@10\"].append(precision_at_k(recs, gt, k=K))\n",
    "        metrics[\"recall@10\"].append(recall_at_k(recs, gt, k=K))\n",
    "        metrics[\"map@10\"].append(apk(recs, gt, k=K))\n",
    "        metrics[\"ndcg@10\"].append(ndcg_at_k(recs, gt, k=K))\n",
    "\n",
    "    mean_metrics = {name: np.mean(values) for name, values in metrics.items()}\n",
    "    results[model_name] = mean_metrics\n",
    "\n",
    "print(\"\\n=== Model Performance Summary ===\")\n",
    "\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\n{model_name}\")\n",
    "    for metric_name in metric_names:\n",
    "        print(f\"{metric_name}: {metrics.get(metric_name, 0.0):.4f}\")\n",
    "    print(f\"n_users_eval: {num_users_evaluated}\")\n",
    "\n",
    "print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c864264b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 1 — Popularity@10: [53, 167, 3905, 3245, 2503, 1164, 2930, 2444, 2905, 2019]\n",
      "\n",
      "--- 9) Top-10 Recommendations for 5 Sample Users from all the 3 different models ---\n",
      "User 2 — Popularity@10: [53, 167, 3905, 3245, 2503, 1164, 2930, 2444, 2905, 2019]\n",
      "\n",
      "--- 9) Top-10 Recommendations for 5 Sample Users from all the 3 different models ---\n",
      "User 3 — Popularity@10: [53, 167, 3905, 3245, 2503, 1164, 2930, 2444, 2905, 2019]\n",
      "\n",
      "--- 9) Top-10 Recommendations for 5 Sample Users from all the 3 different models ---\n",
      "User 4 — Popularity@10: [53, 167, 3905, 3245, 2503, 1164, 2930, 2444, 2905, 2019]\n",
      "\n",
      "--- 9) Top-10 Recommendations for 5 Sample Users from all the 3 different models ---\n",
      "User 5 — Popularity@10: [53, 167, 3905, 3245, 2503, 1164, 2930, 2444, 2905, 2019]\n",
      "\n",
      "--- 9) Top-10 Recommendations for 5 Sample Users from all the 3 different models ---\n",
      "\n",
      "User: 1\n",
      "  > Model A (Popularity Recs):\n",
      "    1. Lamerica (1994)\n",
      "    2. Feast of July (1995)\n",
      "    3. Specials, The (2000)\n",
      "    4. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "    5. Apple, The (Sib) (1998)\n",
      "    6. Two or Three Things I Know About Her (1966)\n",
      "    7. Return with Honor (1998)\n",
      "    8. 24 7: Twenty Four Seven (1997)\n",
      "    9. Sanjuro (1962)\n",
      "    10. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "  > Model B (Item-CF Recs):\n",
      "    1. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "    2. Raiders of the Lost Ark (1981)\n",
      "    3. Shawshank Redemption, The (1994)\n",
      "    4. Toy Story (1995)\n",
      "    5. Groundhog Day (1993)\n",
      "    6. Silence of the Lambs, The (1991)\n",
      "    7. Pulp Fiction (1994)\n",
      "    8. Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "    9. Ghostbusters (1984)\n",
      "    10. Beetlejuice (1988)\n",
      "  > Model C (Content-Based Recs):\n",
      "    1. Watership Down (1978)\n",
      "    2. Pollyanna (1960)\n",
      "    3. Wide Awake (1998)\n",
      "    4. Babe (1995)\n",
      "    5. This Is Spinal Tap (1984)\n",
      "    6. Far Off Place, A (1993)\n",
      "    7. Lady and the Tramp (1955)\n",
      "    8. Little Mermaid, The (1989)\n",
      "    9. Hercules (1997)\n",
      "    10. Lethal Weapon 2 (1989)\n",
      "\n",
      "User: 2\n",
      "  > Model A (Popularity Recs):\n",
      "    1. Lamerica (1994)\n",
      "    2. Feast of July (1995)\n",
      "    3. Specials, The (2000)\n",
      "    4. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "    5. Apple, The (Sib) (1998)\n",
      "    6. Two or Three Things I Know About Her (1966)\n",
      "    7. Return with Honor (1998)\n",
      "    8. 24 7: Twenty Four Seven (1997)\n",
      "    9. Sanjuro (1962)\n",
      "    10. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "  > Model B (Item-CF Recs):\n",
      "    1. Fargo (1996)\n",
      "    2. Star Wars: Episode IV - A New Hope (1977)\n",
      "    3. Pulp Fiction (1994)\n",
      "    4. Men in Black (1997)\n",
      "    5. Schindler's List (1993)\n",
      "    6. Godfather, The (1972)\n",
      "    7. Die Hard (1988)\n",
      "    8. Back to the Future (1985)\n",
      "    9. E.T. the Extra-Terrestrial (1982)\n",
      "    10. L.A. Confidential (1997)\n",
      "  > Model C (Content-Based Recs):\n",
      "    1. Diva (1981)\n",
      "    2. Breathless (1983)\n",
      "    3. Bodyguard, The (1992)\n",
      "    4. First Knight (1995)\n",
      "    5. Devil's Own, The (1997)\n",
      "    6. Runaway Train (1985)\n",
      "    7. Lethal Weapon 2 (1989)\n",
      "    8. Lethal Weapon 4 (1998)\n",
      "    9. Lethal Weapon (1987)\n",
      "    10. Best Men (1997)\n",
      "\n",
      "User: 3\n",
      "  > Model A (Popularity Recs):\n",
      "    1. Lamerica (1994)\n",
      "    2. Feast of July (1995)\n",
      "    3. Specials, The (2000)\n",
      "    4. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "    5. Apple, The (Sib) (1998)\n",
      "    6. Two or Three Things I Know About Her (1966)\n",
      "    7. Return with Honor (1998)\n",
      "    8. 24 7: Twenty Four Seven (1997)\n",
      "    9. Sanjuro (1962)\n",
      "    10. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "  > Model B (Item-CF Recs):\n",
      "    1. Batman (1989)\n",
      "    2. Matrix, The (1999)\n",
      "    3. Die Hard (1988)\n",
      "    4. Terminator, The (1984)\n",
      "    5. Terminator 2: Judgment Day (1991)\n",
      "    6. Back to the Future (1985)\n",
      "    7. Total Recall (1990)\n",
      "    8. Lethal Weapon (1987)\n",
      "    9. Fugitive, The (1993)\n",
      "    10. Hunt for Red October, The (1990)\n",
      "  > Model C (Content-Based Recs):\n",
      "    1. Army of Darkness (1993)\n",
      "    2. Romancing the Stone (1984)\n",
      "    3. True Lies (1994)\n",
      "    4. Jewel of the Nile, The (1985)\n",
      "    5. Operation Dumbo Drop (1995)\n",
      "    6. Inspector Gadget (1999)\n",
      "    7. Condorman (1981)\n",
      "    8. Mystery Men (1999)\n",
      "    9. Operation Condor 2 (Longxiong hudi) (1990)\n",
      "    10. Batman Returns (1992)\n",
      "\n",
      "User: 4\n",
      "  > Model A (Popularity Recs):\n",
      "    1. Lamerica (1994)\n",
      "    2. Feast of July (1995)\n",
      "    3. Specials, The (2000)\n",
      "    4. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "    5. Apple, The (Sib) (1998)\n",
      "    6. Two or Three Things I Know About Her (1966)\n",
      "    7. Return with Honor (1998)\n",
      "    8. 24 7: Twenty Four Seven (1997)\n",
      "    9. Sanjuro (1962)\n",
      "    10. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "  > Model B (Item-CF Recs):\n",
      "    1. Terminator, The (1984)\n",
      "    2. Aliens (1986)\n",
      "    3. Die Hard (1988)\n",
      "    4. Matrix, The (1999)\n",
      "    5. Terminator 2: Judgment Day (1991)\n",
      "    6. Indiana Jones and the Last Crusade (1989)\n",
      "    7. Total Recall (1990)\n",
      "    8. Godfather, The (1972)\n",
      "    9. Fugitive, The (1993)\n",
      "    10. Men in Black (1997)\n",
      "  > Model C (Content-Based Recs):\n",
      "    1. Soldier (1998)\n",
      "    2. Army of Darkness (1993)\n",
      "    3. Heavy Metal (1981)\n",
      "    4. Starship Troopers (1997)\n",
      "    5. Tron (1982)\n",
      "    6. Star Wars: Episode I - The Phantom Menace (1999)\n",
      "    7. Spawn (1997)\n",
      "    8. Total Recall (1990)\n",
      "    9. Lost World: Jurassic Park, The (1997)\n",
      "    10. Escape from New York (1981)\n",
      "\n",
      "User: 5\n",
      "  > Model A (Popularity Recs):\n",
      "    1. Lamerica (1994)\n",
      "    2. Feast of July (1995)\n",
      "    3. Specials, The (2000)\n",
      "    4. I Am Cuba (Soy Cuba/Ya Kuba) (1964)\n",
      "    5. Apple, The (Sib) (1998)\n",
      "    6. Two or Three Things I Know About Her (1966)\n",
      "    7. Return with Honor (1998)\n",
      "    8. 24 7: Twenty Four Seven (1997)\n",
      "    9. Sanjuro (1962)\n",
      "    10. Seven Samurai (The Magnificent Seven) (Shichinin no samurai) (1954)\n",
      "  > Model B (Item-CF Recs):\n",
      "    1. Groundhog Day (1993)\n",
      "    2. Shakespeare in Love (1998)\n",
      "    3. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
      "    4. Ed Wood (1994)\n",
      "    5. Schindler's List (1993)\n",
      "    6. Full Monty, The (1997)\n",
      "    7. Fugitive, The (1993)\n",
      "    8. Boogie Nights (1997)\n",
      "    9. Crying Game, The (1992)\n",
      "    10. Men in Black (1997)\n",
      "  > Model C (Content-Based Recs):\n",
      "    1. Lethal Weapon 4 (1998)\n",
      "    2. Lethal Weapon (1987)\n",
      "    3. Best Men (1997)\n",
      "    4. Man Bites Dog (C'est arrivé près de chez vous) (1992)\n",
      "    5. Lethal Weapon 3 (1992)\n",
      "    6. Lethal Weapon 2 (1989)\n",
      "    7. Midnight in the Garden of Good and Evil (1997)\n",
      "    8. House of Yes, The (1997)\n",
      "    9. Emma (1996)\n",
      "    10. Broadcast News (1987)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 10) Report top‑N for 5 users — TODO\n",
    "sample_users = list(users)[:5]\n",
    "for u in sample_users:\n",
    "    seen = train_df.loc[train_df[user_col]==u, item_col].unique()\n",
    "    pop_recs = recommend_popularity(u, k=10, seen_items=seen)\n",
    "    print(f\"User {u} — Popularity@10:\", pop_recs)\n",
    "    # TODO: also show your model's top‑10 for comparison\n",
    "    \n",
    "    print(\"\\n--- 9) Top-10 Recommendations for 5 Sample Users of different three models A,B,C ---\")\n",
    "\n",
    "movie_titles = df[[item_col, 'Title']].drop_duplicates().set_index(item_col)['Title'].to_dict()\n",
    "\n",
    "sample_users = list(users_to_evaluate)[:5]\n",
    "\n",
    "for u in sample_users:\n",
    "\n",
    "    seen_ids = train_df.loc[train_df[user_col] == u, item_col].unique()\n",
    "    \n",
    "    pop_recs_ids = recommend_popularity(u, k=10)\n",
    "    itemcf_recs_ids = recommend_itemcf(u, k=10)\n",
    "    cbf_recs_ids = recommend_content_based(u, k=10)\n",
    "\n",
    "    pop_recs_titles = [movie_titles.get(mid, f\"ID {mid} (Title Missing)\") for mid in pop_recs_ids]\n",
    "    itemcf_recs_titles = [movie_titles.get(mid, f\"ID {mid} (Title Missing)\") for mid in itemcf_recs_ids]\n",
    "    cbf_recs_titles = [movie_titles.get(mid, f\"ID {mid} (Title Missing)\") for mid in cbf_recs_ids]\n",
    "    \n",
    "    print(f\"\\nUser: {u}\")\n",
    "    \n",
    "    print(f\"  > Model A (Popularity Recs):\")\n",
    "    for i, title in enumerate(pop_recs_titles):\n",
    "         print(f\"    {i+1}. {title}\")\n",
    "         \n",
    "    print(f\"  > Model B (Item-CF Recs):\")\n",
    "    for i, title in enumerate(itemcf_recs_titles):\n",
    "        print(f\"    {i+1}. {title}\")\n",
    "        \n",
    "    print(f\"  > Model C (Content-Based Recs):\")\n",
    "    for i, title in enumerate(cbf_recs_titles):\n",
    "        print(f\"    {i+1}. {title}\")\n",
    "    \n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e159c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Brief Discussion (write here)\n",
    " ### What worked well? What didn’t?\n",
    "  The points for worked well are:\n",
    "  - Model B (Item-CF) and Model C (Content-Based) achieved significantly higher Precision@10 scores than the Popularity baseline (Model A). This means when these models made a list of 10 recommendations, a greater percentage of those items were actually relevant\n",
    "  - Model B (Item- CF )performed the best among across the ranking metrics (Recall@10, MAP@10, and NDCG@10),Here it tells us that the collaborative filtering is highly effective at looking into the user preferences and providing the relevant novel recommendations.\n",
    "  - Model C was  executed well the content based filter model where it created the personalized user profiles where it demonstrates that it handles the item features and provide the result that matches the user preference.\n",
    "  \n",
    "  The points that did not work well is:\n",
    "  - Model A (Popularity model or baseline) where it provided the lowest score across all the boards for the metrics evaluated.It fails the critical test of recommendation system of recommending the relevant items.\n",
    "  - All models, particularly Item-CF, has high matrix sparsity, where the similarity calculations and collaborative signals are based on very limited overlap between users/items. The Content-Based model also relies on the relatively coarse-grained feature of movie genres.\n",
    "\n",
    "### How do the two approaches compare (strengths/weaknesses)?\n",
    "\n",
    " - Model A (Popularity): \n",
    " Strengths:  Extremely fast to compute, serves   as a robust cold-start user fallback.\n",
    " Weakness : Zero personalization; fails to capture individuality.\n",
    " \n",
    " - Model B (Item -CF) : \n",
    " Strengths: High personalization, excellent at recommending niche items based on community recommends.\n",
    " Weakness : Susceptible to the cold-start item problem,computation scales poorly with the number of items.\n",
    " \n",
    " - Model C(Content Based) : \n",
    " Strengths : Solves the cold-start item problem (can recommend a new movie if its genres are known); interpretable.\n",
    " Weakness: Overspecialization (the \"filter bubble\"); poor at suggesting items outside a user's past genre history.\n",
    "\n",
    "\n",
    "\n",
    "### Any evidence of popularity bias or cold‑start issues?\n",
    "\n",
    "Popularity Bias Issues: Popular items probably appear frequently across different users recommendation lists,\n",
    "Model A demonstrates clear popularity bias, as every user receives the exact same set of top-rated, most-frequently-seen items. Model B and C reduce this significantly by prioritizing relevance to the user's history.\n",
    "\n",
    "Cold Start Isues.By enforcing a minimum interaction threshold of 5 during preprocessing, the issue of recommending to users with no history was largely avoided for Models B and C. Model B (Item-CF) is incapable of recommending brand-new movies because they lack the necessary rating data to compute item-to-item similarity. Model C effectively solves this, as it only requires the new movie's genre (content features) to match the user's profile.\n",
    "\n",
    "### Possible next steps if you had more time (blending, hyperparameters, side features).\n",
    "\n",
    "- The most immediate improvement would be to create a hybrid system, perhaps by linearly blending the scores of Model B (Item-CF) and Model C (CBF). This blend would leverage Item-CF's strong personalization while using CBF's ability to recommend new or niche items based on content.\n",
    "\n",
    "-  Enhance Model C by incorporating more detailed content features beyond simple genres, such as TF-IDF on movie titles or plot summaries, to create richer user and item representations.\n",
    "\n",
    "- Using Matrix Factorization where it typically handles sparsity better and yields superior performance metrics compared to neighborhood-based methods.\n",
    "\n",
    "## Grading Rubric (100 pts)\n",
    "- Data prep & clarity (10)\n",
    "- Correct split + rationale (15)\n",
    "- Baseline + **one additional** approach (30)\n",
    "- Metrics & evaluation (25)\n",
    "- Analysis & discussion + top‑N examples (20)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488032d-433e-4d98-9f39-8704be934018",
   "metadata": {},
   "source": [
    "## Sample Result (for reference only)\n",
    "\n",
    "When you complete your evaluation, you should produce a summary table like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb05247-7482-4c11-afb2-93515314ca66",
   "metadata": {},
   "source": [
    "![Sample Results](Sample_Results.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318704f8-a86e-4c8c-8206-6e320bc61242",
   "metadata": {},
   "source": [
    "\n",
    "### Guidelines\n",
    "- Do not worry if your numbers differ slightly; they depend on preprocessing, parameters, and randomness.  \n",
    "- The important part is that **Model_B typically performs better than Model_A**, and Model_C is somewhere in between.  \n",
    "- In your write-up, focus on *why* these differences occur (e.g., handling of user preferences, cold start, popularity bias).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8639c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
